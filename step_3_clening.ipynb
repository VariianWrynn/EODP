{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import re\n",
    "#imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the data \n",
    "data = pd.read_csv('data.csv')\n",
    "#remove the first column and the second column\n",
    "data = data.drop(data.columns[0], axis=1)\n",
    "data = data.drop(data.columns[0], axis=1)\n",
    "#remove the \"Processed-Title\" column in data \n",
    "data = data.drop('Processed-Title', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User-Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get any num\" to num\n",
    "data['User-Age'] = data['User-Age'].str.extract('(\\d+)')\n",
    "#get the data type to be int\n",
    "data['User-Age'] = data['User-Age'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 33.,  21.,  31.,  14.,  29.,  11.,  27.,  22.,  34.,  25.,  70.,\n",
       "        54.,  24.,  48.,  65.,  62.,  32.,  42.,  50.,  56.,  17.,  40.,\n",
       "        35.,  52.,  26.,  63.,  60.,  28.,  55.,  30.,  51.,  46.,  59.,\n",
       "        57.,  39.,  15.,  47.,  20.,  23.,  49.,  36.,  37.,  53.,  41.,\n",
       "        75.,  69.,  61.,  16.,  43.,  45.,  64.,  18.,  44.,  68.,  71.,\n",
       "        19.,  66.,  38.,  13.,  78.,  58.,  76.,  67.,  80.,  83.,  73.,\n",
       "        72.,  74.,  12.,   9.,  10.,  77.,  97.,   8.,  90.,  79.,  81.,\n",
       "        82., 100.,   7.,  93.,  99.,  84.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get any age > 100 to NAN\n",
    "data.loc[data['User-Age'] > 100, 'User-Age'] = np.nan\n",
    "#get any age < 5 to NAN\n",
    "data.loc[data['User-Age'] < 5, 'User-Age'] = np.nan\n",
    "\n",
    "#create a pipeline to impute the missing values to median\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "#fit the pipeline to the User-Age column\n",
    "pipeline.fit(data[['User-Age']])\n",
    "#transform the User-Age column\n",
    "data['User-Age'] = pipeline.transform(data[['User-Age']])\n",
    "\n",
    "#summary statistics\n",
    "data['User-Age'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User-Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get any str\" to str\n",
    "data['User-Country'] = data['User-Country'].str.extract('([a-zA-Z]+)')\n",
    "\n",
    "data['User-Country'].unique().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_corrections = {\n",
    "    'usa': 'United States',\n",
    "    'united': 'United Kingdom',  # Assuming 'united' might be shorthand for 'United Kingdom'\n",
    "    'hong': 'Hong Kong',  # Assuming meant to be 'Hong Kong'\n",
    "    'czech': 'Czech Republic',\n",
    "    'costa': 'Costa Rica',\n",
    "    'south': 'South Korea',  # Assuming it refers to 'South Korea', could also be 'South Africa'\n",
    "    'ua': 'Ukraine',  # Common abbreviation\n",
    "    'us': 'United States',\n",
    "    'far': 'Faroe Islands',  # If it is meant to represent 'Faroe Islands'\n",
    "    'rutherford': None,  # Not a country, likely invalid data\n",
    "    'morgan': None,  # Not a country, likely a mistake\n",
    "    'framingham': None,  # City in Massachusetts, not a country\n",
    "    'worcester': None,  # City in Massachusetts, not a country\n",
    "    'van': 'Vanuatu',  # Assuming it's an abbreviation for 'Vanuatu'\n",
    "    'euskal': 'Spain',  # Refers to the Basque region, which is part of Spain\n",
    "    'universe': None,  # Clearly invalid\n",
    "    'quit': None,  # Likely invalid or a typo\n",
    "    'phillipines': 'Philippines',  # Spelling correction\n",
    "    'cayman': 'Cayman Islands',\n",
    "    'caribbean': None,  # Not a single country, too broad\n",
    "    'catalonia': 'Spain',  # Region in Spain, not a separate country\n",
    "    'u': None  # Not clear what country this should refer to\n",
    "    # Add more as necessary\n",
    "}\n",
    "\n",
    "# Replace incorrect country names using the mapping\n",
    "data['User-Country'] = data['User-Country'].replace(country_corrections)\n",
    "\n",
    "valid_countries = ['United States', 'Germany', 'Spain', 'Canada', 'Portugal', 'Australia', 'Indonesia', 'Japan', 'France',\n",
    "                   'Taiwan', 'Italy', 'Malaysia', 'Sweden', 'New Zealand', 'Iran', 'Hong Kong', 'Romania', 'Netherlands',\n",
    "                   'Austria', 'Singapore', 'Guatemala', 'India', 'Israel', 'Philippines', 'Greece', 'Czech Republic', 'Ireland',\n",
    "                   'Switzerland', 'Finland', 'Brazil', 'Slovenia', 'Bulgaria', 'Costa Rica', 'Antarctica', 'Belgium', 'Uruguay',\n",
    "                   'Egypt', 'Algeria', 'Mexico', 'Jamaica', 'South Korea', 'Denmark', 'China', 'Zimbabwe', 'Turkey', 'Belize',\n",
    "                   'Cyprus', 'Ecuador', 'Burma', 'Qatar', 'Kuwait', 'Argentina', 'Iceland', 'Bermuda', 'Bahamas', 'Saudi Arabia',\n",
    "                   'Nepal', 'Peru', 'Russia', 'Pakistan', 'Norway', 'Luxembourg', 'Dominican Republic', 'Albania', 'Macedonia',\n",
    "                   'Kenya', 'Mauritius', 'Chile', 'Venezuela', 'Guinea', 'Poland', 'Honduras', 'Barbados', 'Ukraine', 'Yugoslavia',\n",
    "                   'Thailand', 'Mozambique', 'Ghana', 'United Kingdom']  # Add all valid countries to this list\n",
    "\n",
    "# Filter the DataFrame with the lowercased country names too, and replace lowercase country names with the correct ones\n",
    "valid_countries_lower = [country.lower() for country in valid_countries]\n",
    "data = data[data['User-Country'].isin(valid_countries_lower) |\n",
    "            data['User-Country'].isin(valid_countries)]\n",
    "data['User-Country'] = data['User-Country'].replace({country.lower(): country for country in valid_countries})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['User-Country'].unique()\n",
    "data['User-Country'].unique().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Book-Publisher</th>\n",
       "      <th>User-City</th>\n",
       "      <th>User-State</th>\n",
       "      <th>User-Country</th>\n",
       "      <th>User-Age</th>\n",
       "      <th>Series-Title</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25730.000000</td>\n",
       "      <td>25730</td>\n",
       "      <td>25730.000000</td>\n",
       "      <td>25730</td>\n",
       "      <td>25730</td>\n",
       "      <td>25730.000000</td>\n",
       "      <td>25730</td>\n",
       "      <td>25643</td>\n",
       "      <td>25730</td>\n",
       "      <td>25730</td>\n",
       "      <td>25730.000000</td>\n",
       "      <td>25730</td>\n",
       "      <td>25730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>565</td>\n",
       "      <td>268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>229</td>\n",
       "      <td>4236</td>\n",
       "      <td>486</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0971880107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wild Animus</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Warner Books</td>\n",
       "      <td>toronto</td>\n",
       "      <td>california</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ring</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>556</td>\n",
       "      <td>2108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1557</td>\n",
       "      <td>296</td>\n",
       "      <td>3116</td>\n",
       "      <td>20554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2976</td>\n",
       "      <td>7092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>140323.671901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.879829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984.323397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.699883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>79990.125905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.834800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.753802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.212067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>71705.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>138995.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>210587.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>278851.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              User-ID        ISBN   Book-Rating   Book-Title   Book-Author  \\\n",
       "count    25730.000000       25730  25730.000000        25730         25730   \n",
       "unique            NaN         758           NaN          565           268   \n",
       "top               NaN  0971880107           NaN  Wild Animus  John Grisham   \n",
       "freq              NaN         556           NaN          556          2108   \n",
       "mean    140323.671901         NaN      7.879829          NaN           NaN   \n",
       "std      79990.125905         NaN      1.834800          NaN           NaN   \n",
       "min         51.000000         NaN      1.000000          NaN           NaN   \n",
       "25%      71705.250000         NaN      7.000000          NaN           NaN   \n",
       "50%     138995.000000         NaN      8.000000          NaN           NaN   \n",
       "75%     210587.000000         NaN      9.000000          NaN           NaN   \n",
       "max     278851.000000         NaN     10.000000          NaN           NaN   \n",
       "\n",
       "        Year-Of-Publication Book-Publisher User-City   User-State  \\\n",
       "count          25730.000000          25730     25643        25730   \n",
       "unique                  NaN            229      4236          486   \n",
       "top                     NaN   Warner Books   toronto   california   \n",
       "freq                    NaN           1557       296         3116   \n",
       "mean            1984.323397            NaN       NaN          NaN   \n",
       "std              164.753802            NaN       NaN          NaN   \n",
       "min                0.000000            NaN       NaN          NaN   \n",
       "25%             1996.000000            NaN       NaN          NaN   \n",
       "50%             1999.000000            NaN       NaN          NaN   \n",
       "75%             2001.000000            NaN       NaN          NaN   \n",
       "max             2004.000000            NaN       NaN          NaN   \n",
       "\n",
       "         User-Country      User-Age Series-Title    Genre  \n",
       "count           25730  25730.000000        25730    25730  \n",
       "unique             76           NaN           86        9  \n",
       "top     United States           NaN         ring  Fantasy  \n",
       "freq            20554           NaN         2976     7092  \n",
       "mean              NaN     34.699883          NaN      NaN  \n",
       "std               NaN     10.212067          NaN      NaN  \n",
       "min               NaN      7.000000          NaN      NaN  \n",
       "25%               NaN     29.000000          NaN      NaN  \n",
       "50%               NaN     33.000000          NaN      NaN  \n",
       "75%               NaN     38.000000          NaN      NaN  \n",
       "max               NaN    100.000000          NaN      NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summarise every column\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('cleaned_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
